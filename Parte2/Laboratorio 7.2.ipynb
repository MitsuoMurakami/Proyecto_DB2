{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr2ewyCfSkO1",
    "deepnote_app_block_visible": true,
    "cell_id": "f72575afc9b54cf98a7b62a31329ed15",
    "deepnote_cell_type": "markdown"
   },
   "source": "# Laboratorio 7.2",
   "block_group": "fadba266b21a4c58abdca8ad41c53e19"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXBNvBLxTnTy",
    "deepnote_app_block_visible": true,
    "cell_id": "88673c7c872e45a89a3844c73b31e8b8",
    "deepnote_cell_type": "markdown"
   },
   "source": "### 2- Similitud de coseno",
   "block_group": "9b8129c52c7844db818420b301ccf211"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k4uL88ZGbiCf",
    "source_hash": null,
    "execution_start": 1716474222946,
    "execution_millis": 615,
    "deepnote_to_be_reexecuted": false,
    "deepnote_app_block_visible": true,
    "cell_id": "ad3c009f68734c60b8e21f88547d116a",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "end_time": "2024-10-24T09:52:39.526767Z",
     "start_time": "2024-10-24T09:52:39.502823Z"
    }
   },
   "source": [
    "\n",
    "from heapq import heapify\n",
    "\n",
    "\n",
    "def compute_tfidf(collection):\n",
    "    # calcular los pesos TF_IDF para cada documento de la coleccion\n",
    "\n",
    "    allWords = set([word for doc in collection for word in doc])\n",
    "    N = len(collection)\n",
    "    matrix = []\n",
    "    for word in allWords:\n",
    "        tf_docs = []\n",
    "        for doc in collection:\n",
    "            tf = np.log10(1 + doc.count(word))\n",
    "            tf_docs.append(tf)\n",
    "        df = [1 if tf > 0 else 0 for tf in tf_docs]\n",
    "\n",
    "        df = np.log10(N / np.sum(df))\n",
    "        tfidf_s = np.array(tf_docs) * df\n",
    "        matrix.append(tfidf_s)\n",
    "    tfidf_docs = np.array(matrix).T\n",
    "    return tfidf_docs, allWords\n",
    "\n",
    "\n",
    "def cosine_sim(Q, Doc):\n",
    "    return np.dot(Q, Doc) / (np.linalg.norm(Q) * np.linalg.norm(Doc))\n",
    "\n",
    "\n",
    "textos_tfidf, allWords = compute_tfidf(textos_procesados)\n",
    "\n",
    "matriz = []\n",
    "for doc1 in textos_tfidf:\n",
    "    row = []\n",
    "    for doc2 in textos_tfidf:\n",
    "        row.append(cosine_sim(doc1, doc2))\n",
    "    matriz.append(row)\n",
    "\n",
    "i = 1\n",
    "for row in matriz:\n",
    "    print(f'Archivo{i}', [float(round(x, 2)) for x in row])\n",
    "    i = i + 1\n"
   ],
   "block_group": "14f5fdcbef054bbe897337ebc19f051a",
   "outputs_reference": "dbtable:cell_outputs/4071c1e2-9bbd-4fe0-8c07-dc800cc0446a",
   "content_dependencies": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo1 [1.0, 0.05, 0.04, 0.01, 0.06, 0.07]\n",
      "Archivo2 [0.05, 1.0, 0.05, 0.07, 0.05, 0.04]\n",
      "Archivo3 [0.04, 0.05, 1.0, 0.08, 0.03, 0.1]\n",
      "Archivo4 [0.01, 0.07, 0.08, 1.0, 0.07, 0.08]\n",
      "Archivo5 [0.06, 0.05, 0.03, 0.07, 1.0, 0.03]\n",
      "Archivo6 [0.07, 0.04, 0.1, 0.08, 0.03, 1.0]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deepnote_app_block_visible": true,
    "cell_id": "6d8495d05ffa451c9fced921fd79b555",
    "deepnote_cell_type": "markdown"
   },
   "source": "## P4- Similitud de coseno con el Indice Invertido",
   "block_group": "cd5ca025c8ab423f9cdb7ca507699867"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deepnote_app_block_visible": true,
    "cell_id": "4b61a710a23643a695c0c0082646f4cf",
    "deepnote_cell_type": "markdown"
   },
   "source": "### 1- Estructura del índice invertido en Python:",
   "block_group": "525622409eb5419090a19704f6f60be3"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": null,
    "deepnote_to_be_reexecuted": true,
    "deepnote_app_block_visible": true,
    "cell_id": "c2d154f448dc41d8b348eb9d9c1b48bf",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "end_time": "2024-10-24T09:52:39.611088Z",
     "start_time": "2024-10-24T09:52:39.607071Z"
    }
   },
   "source": "\"\"\"\nindex = {\nw1 : [(doc1, tf_w1_doc1), (doc3, tf_w1_doc3),(doc4, tf_w1_doc4),(doc10, tf_w1_doc10)],\nw2 : [(doc1, tf_w2_doc1 ), (doc2, tf_w2_doc2)],\nw3 : [(doc2, tf_w3_doc2), (doc3, tf_w3_doc3),(doc7, tf_w3_doc7)],\n}\n\nidf = {\nw1 : idf_w1,\nw2 : idf_w2,\nw3 : idf_w3,\n}\n\nlength ={\ndoc1: norm_doc1,\ndoc2: norm_doc2,\ndoc3: norm_doc3,\n...\n}\n\"\"\"",
   "block_group": "4a931760a1684d6d98c15bfd62be9027",
   "outputs_reference": null,
   "content_dependencies": null,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nindex = {\\nw1 : [(doc1, tf_w1_doc1), (doc3, tf_w1_doc3),(doc4, tf_w1_doc4),(doc10, tf_w1_doc10)],\\nw2 : [(doc1, tf_w2_doc1 ), (doc2, tf_w2_doc2)],\\nw3 : [(doc2, tf_w3_doc2), (doc3, tf_w3_doc3),(doc7, tf_w3_doc7)],\\n}\\n\\nidf = {\\nw1 : idf_w1,\\nw2 : idf_w2,\\nw3 : idf_w3,\\n}\\n\\nlength ={\\ndoc1: norm_doc1,\\ndoc2: norm_doc2,\\ndoc3: norm_doc3,\\n...\\n}\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deepnote_app_block_visible": true,
    "cell_id": "5ccacf43c13742dbaf088ceb45b5c621",
    "deepnote_cell_type": "markdown"
   },
   "source": "# SPIMI ",
   "block_group": "87ecd9a159724ec4a420f04e467a3c32"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "d90d743f",
    "execution_start": 1728075206132,
    "execution_millis": 0,
    "execution_context_id": "1e7e5f1c-d694-4140-b3f8-562293cc6b23",
    "deepnote_app_block_visible": true,
    "cell_id": "dca6b48d30794b3e86f5da878ce5451b",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "end_time": "2024-11-13T03:11:51.025294Z",
     "start_time": "2024-11-13T03:11:51.011719Z"
    }
   },
   "source": [
    "import pickle\n",
    "import csv\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import os\n",
    "import sys\n",
    "import heapq\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "class InvertIndexSPIMI:\n",
    "    def __init__(self):\n",
    "        # self.index_file = index_file\n",
    "        # self.index = {}\n",
    "        # self.idf = {}\n",
    "        # self.length = {}\n",
    "        self.stemmer = SnowballStemmer('spanish')\n",
    "        self.stoplist = []\n",
    "        self.preprocessed_words_file = \"preprocessed_words.txt\"\n",
    "        self.spimi_file = \"spimi_blocks.txt\"\n",
    "        self.id_block = 0\n",
    "        self.free_memory_available = 500000  # 0.5 MB\n",
    "        self.current_line_preprocessed_words_file = 0\n",
    "        self.end_preprocessed_words_file = 0\n",
    "        self.min_heap_size = 500\n",
    "        self.index = \"index.txt\"\n",
    "     \n",
    "        #fd\n",
    " # TODO Process the text to create many blocks using the SPIMI algorithm\n",
    "    def load_stop_list(self, filename=\"english_stoplist.txt\"):\n",
    "        with open(filename, encoding=\"utf-8\") as file:\n",
    "            self.stoplist = [line.rstrip().lower() for line in file]\n",
    "\n",
    "    def preprocesamiento_aux(self, texto):\n",
    "        words = []\n",
    "        # tokenizar\n",
    "        texto_tok = texto.lower()\n",
    "        texto_tok = re.sub(r'[^a-zA-Z_À-ÿ]', ' ', texto)\n",
    "        words = nltk.word_tokenize(texto_tok, language='english')\n",
    "        # filtrar stopwords\n",
    "        words = [word for word in words if word not in self.stoplist]\n",
    "        # reducir palabras\n",
    "        words = [self.stemmer.stem(word) for word in words]\n",
    "        return words\n",
    "    def get_list_tf(self, tokens, id):\n",
    "        # compute the term frequency for each word in the document with id\n",
    "        tf = {}\n",
    "        for word in tokens:\n",
    "            if word not in tf:\n",
    "                tf[word] = 1\n",
    "            else:\n",
    "                tf[word] += 1\n",
    "        return [(id, word, tf[word]) for word in tf]\n",
    "        \n",
    "    def preprocesamiento(self, pathOfFile):\n",
    "        # only do the preprocess if the file doesnt exist\n",
    "        if os.path.exists(self.preprocessed_words_file):\n",
    "            return\n",
    "        \n",
    "        # List of tokens for each song\n",
    "        preprocessed_song = []           \n",
    "   \n",
    "        with open(pathOfFile, newline='', encoding='utf-8') as file, open(self.preprocessed_words_file, 'w') as preprocessed_words:\n",
    "            songs_file = csv.reader(file, delimiter=',', quotechar='\"')\n",
    "            # counter used as id for each song\n",
    "            counter_rows = 0\n",
    "            for row in songs_file:\n",
    "                # skip the header\n",
    "                if counter_rows == 0:\n",
    "                    counter_rows += 1\n",
    "                    continue\n",
    "                # track_name , artist_name, lyrics\n",
    "                song_details = row[1] + \" \" + row[2] + \" \" + row[3]\n",
    "                # get list of tokens for each song\n",
    "                preprocessed_song = self.preprocesamiento_aux(song_details)\n",
    "                # get the tf for each word in the song\n",
    "                list_tf_song = self.get_list_tf(preprocessed_song, counter_rows)\n",
    "                counter_rows += 1\n",
    "                # write the relative_id_song, word, tf in each line of file\n",
    "                for tf in list_tf_song:\n",
    "                    preprocessed_words.write(str(tf) + \"\\n\")\n",
    "    def strToList(self, string):\n",
    "        string = string[:-1] \n",
    "        string = string[1:-1]\n",
    "        tup = string.split(\", \")\n",
    "        return [int(tup[0]), tup[1], int(tup[2])]\n",
    "    \n",
    "    # receive the token list which is a list of tuples (id, word, tf)\n",
    "    def spimi_invert(self):\n",
    "        blocks_directory = r\".\\blocks\"\n",
    "        if not os.path.exists(blocks_directory):\n",
    "            os.makedirs(blocks_directory)\n",
    "        output_file = r\".\\blocks\\block_\" + str(self.id_block) + \".txt\"\n",
    "        dictionary = {}\n",
    "        with open(self.preprocessed_words_file, 'r') as preprocessed_words, open(output_file, 'w') as block:\n",
    "            print(\"In block:\", self.id_block)\n",
    "            preprocessed_words.seek(self.current_line_preprocessed_words_file)\n",
    "            while sys.getsizeof(dictionary) < self.free_memory_available:\n",
    "                # read the next token\n",
    "                token = preprocessed_words.readline()\n",
    "                if not token:\n",
    "                    self.end_preprocessed_words_file = 1\n",
    "                    break\n",
    "                # convert the string to a list of relative_id_song, word and its tf\n",
    "                token = self.strToList(token)\n",
    "                if token[1] not in dictionary:\n",
    "                    dictionary[token[1]] = [(token[0], token[2])]\n",
    "                else:\n",
    "                    dictionary[token[1]].append((token[0], token[2]))\n",
    "            self.current_line_preprocessed_words_file = preprocessed_words.tell()\n",
    "            sorted_terms = sorted(dictionary.keys())\n",
    "            for term in sorted_terms:\n",
    "                block.write(term + \":\" + str(dictionary[term]) + \"\\n\")\n",
    "        self.id_block += 1\n",
    "        \n",
    "        \n",
    "    def create_spimi_blocks(self): \n",
    "        # create a directory to store the blocks\n",
    "        blocks_directory = r\".\\blocks\"\n",
    "        if not os.path.exists(blocks_directory):\n",
    "            os.makedirs(blocks_directory)\n",
    "        # read the preprocessed words file as it has the tf for each token in each song, then created size \n",
    "        # limit blocks with spimi algorithm \n",
    "        while(not self.end_preprocessed_words_file):  \n",
    "            self.spimi_invert()\n",
    "       \n",
    "   \n",
    "    \"\"\"\n",
    "    Para el merge se abriran todos los bloques simultaneamente, se leera la primera palabras de cada bloque,\n",
    "    luego usando una pritority queue se obtendra el menor termino lexicografico y se combinaran todas las \n",
    "    listas existentes para dicho termino. Se escribira en un nuevo archivo y se repetira el proceso hasta \n",
    "    que no haya mas.\n",
    "    Dado que se el minHeap se inicializa con 1 termino de cada bloque y cada vez que se hace pop, se pushea \n",
    "    un term del mismo bloque, se garantiza que el heap tiene un term de cada bloque a menos que se haya llegado\n",
    "    al final de un bloque. Ademas, se itera hasta que el heap este vacio, por lo que se garantiza el \n",
    "    recorrido total por todos los bloques.\n",
    "    \"\"\"\n",
    "   \n",
    "    def merge_spimi_blocks(self):\n",
    "        # get all the block names\n",
    "        blocks_name = os.listdir(r\".\\blocks\")\n",
    "        # open all the blocks\n",
    "        opened_blocks = []\n",
    "        for block_name in blocks_name:\n",
    "            opened_blocks.append(open(\".\\\\blocks\\\\\" + block_name, 'r'))\n",
    "        # min heap for terms\n",
    "        terms_from_all_blocks = []\n",
    "        # read the first term from each block\n",
    "        counter_opened_block = 0\n",
    "        for opened_block in opened_blocks:\n",
    "            term = opened_block.readline()\n",
    "            if term:\n",
    "                term = term.split(\":\")\n",
    "                # push (term, [...], block_number) to the heap\n",
    "                heapq.heappush(terms_from_all_blocks, (term[0], term[1], counter_opened_block))\n",
    "            counter_opened_block += 1\n",
    "        # merge the blocks in index.txt\n",
    "        with open(self.index, 'w') as index:\n",
    "            prev_top_term = None\n",
    "            temp_prev_top_term = []\n",
    "            # iterate until the heap is empty\n",
    "            while len(terms_from_all_blocks) > 0:\n",
    "                # obtenemos el menor termino lexicograficamente \n",
    "                current_top_term = heapq.heappop(terms_from_all_blocks)\n",
    "                # if the previous term is the same as the current term, merge their posting lists\n",
    "                if prev_top_term and prev_top_term[0] == current_top_term[0]:\n",
    "                    # convert the string to a list of tuples if necessary\n",
    "                    if isinstance(prev_top_term[1], str):                \n",
    "                        temp_prev_top_term = eval(prev_top_term[1])\n",
    "                    # posting list of current term is always a str\n",
    "                    temp_current_top_term = eval(current_top_term[1])\n",
    "                    # merge posting lists\n",
    "                    temp_prev_top_term.extend(temp_current_top_term)\n",
    "                    # update the posting list and block number \n",
    "                    prev_top_term =(prev_top_term[0], temp_prev_top_term, current_top_term[2])\n",
    "                    \n",
    "                else:\n",
    "                    prev_top_term = current_top_term\n",
    "                    # write the current term and check the type to add or no the '\\n'\n",
    "                    if isinstance(current_top_term[1], str):\n",
    "                        index.write(current_top_term[0] + \":\" + current_top_term[1])\n",
    "                    elif isinstance(current_top_term[1], list):\n",
    "                        index.write(current_top_term[0] + \":\" + str(current_top_term[1]) + \"\\n\")\n",
    "                # read the next term from the block of the current term\n",
    "                next_term_same_block = opened_blocks[current_top_term[2]].readline()\n",
    "                if next_term_same_block:\n",
    "                       next_term_same_block = next_term_same_block.split(\":\")\n",
    "                       # push the next term to the heap\n",
    "                       heapq.heappush(terms_from_all_blocks, (next_term_same_block[0], next_term_same_block[1], current_top_term[2]))\n",
    "        # close blocks\n",
    "        for opened_block in opened_blocks:\n",
    "            opened_block.close()\n",
    "    \n",
    "        # TODO: remove all the blocks from disk. I'm not removing because reading the blocks from disk\n",
    "        # is faster than processing the text again\n",
    "        \n",
    "        # TODO: calculate idf\n",
    "                \n",
    "            \n",
    "            \n",
    "    def build (self, pathOfFile):\n",
    "        self.load_stop_list()\n",
    "        self.preprocesamiento(pathOfFile)\n",
    "        self.create_spimi_blocks()\n",
    "        self.merge_spimi_blocks()\n",
    "        \n",
    "        \n",
    " #    def building(self, pathOfFile):\n",
    " #        columna_procesada = collection_text.columns[position_text]\n",
    " #        rows = collection_text.shape[0]\n",
    " #        indice = {}\n",
    " #        idf_doc = {}\n",
    " #        lenght_doc = {}\n",
    " # \n",
    " #        # build the inverted index with the collection\n",
    " #        # compute the tf\n",
    " # \n",
    " #        for i in range(rows):\n",
    " #            texto = collection_text[columna_procesada][i]\n",
    " #            texto = preprocesamiento(texto)\n",
    " #            for word in texto:\n",
    " #                if word not in indice:\n",
    " #                    indice[word] = [(i, 1)]\n",
    " #                else:\n",
    " #                    for j, (docx, freq) in enumerate(indice[word]):\n",
    " #                        # si la palabra ya esta en el documento no se agrega una nueva por el break\n",
    " #                        if docx == i:\n",
    " #                            indice[word][j] = (docx, freq + 1)\n",
    " #                            break\n",
    " #                    else:\n",
    " #                        indice[word].append((i, 1))\n",
    " # \n",
    " #        # compute the idf\n",
    " #        idf_doc = {word: np.log10(rows / len(indice[word])) for word in indice}\n",
    " #        # compute the length (norm)\n",
    " #        for word in indice:\n",
    " #            for doc, tf in indice[word]:\n",
    " #                tfidf = (1 + np.log10(tf)) * idf_doc[word]\n",
    " #                if doc not in lenght_doc:\n",
    " #                    lenght_doc[doc] = tfidf ** 2\n",
    " #                else:\n",
    " #                    lenght_doc[doc] += tfidf ** 2\n",
    " #        for doc in lenght_doc:\n",
    " #            lenght_doc[doc] = np.sqrt(lenght_doc[doc])\n",
    " #        # store in disk\n",
    " #        with open(self.index_file, 'wb') as file:\n",
    " #            pickle.dump([indice, idf_doc, lenght_doc], file)\n",
    " #        #print(\"index constrido\")\n",
    " # # FIXME 1: Adaptar todos los metodos de abajo\n",
    " #    def retrieval(self, query, k):\n",
    " #        self.load_index()\n",
    " #        # diccionario para el score\n",
    " #        score = {}\n",
    " #        # preprocesar la query: extraer los terminos unicos\n",
    " #        post_query = preprocesamiento(query)\n",
    " #        # calcular el tf-idf del query\n",
    " # \n",
    " #        query_words = set(post_query)\n",
    " #        query_tfidf = []\n",
    " #        for wordq in query_words:\n",
    " #            if wordq in self.idf:\n",
    " #                idfq = self.idf[wordq]\n",
    " #            else:\n",
    " #                idfq = 0\n",
    " #            query_tfidf.append((1 + np.log10(post_query.count(wordq))) * idfq)\n",
    " #            # normalizar el query\n",
    " #        query_norm = np.sqrt(sum([q ** 2 for q in query_tfidf]))\n",
    " #        query_tfidf = [q / query_norm for q in query_tfidf]\n",
    " #        query_words = list(query_words)\n",
    " # \n",
    " #        # aplicar similitud de coseno y guardarlo en el diccionario score\n",
    " #        for word in query_words:\n",
    " #            if word in self.index:\n",
    " #                idf = self.idf[word]\n",
    " #                for doc, tf in self.index[word]:\n",
    " #                    if doc not in score:\n",
    " #                        score[doc] = 0\n",
    " #                    score[doc] += query_tfidf[query_words.index(word)] * tf * idf\n",
    " #        for d in score:\n",
    " #            score[d] = score[d] / self.length[d]\n",
    " # \n",
    " #        # ordenar el score de forma descendente\n",
    " #        result = sorted(score.items(), key=lambda tup: tup[1], reverse=True)\n",
    " #        # retornamos los k documentos mas relevantes (de mayor similitud al query)\n",
    " #        #print(\"resultados listos\")\n",
    " # \n",
    " #        return result[:k]\n",
    " # \n",
    " #    def load_index(self):\n",
    " #        # load index from disk      \n",
    " #        all_dics = []\n",
    " #        try:\n",
    " #            with open(self.index_file, 'rb') as file:\n",
    " #                all_dics = pickle.load(file)\n",
    " #            self.index = all_dics[0]\n",
    " #            self.idf = all_dics[1]\n",
    " #            self.length = all_dics[2]\n",
    " #            # print(\"index cargado\")\n",
    " #        except FileNotFoundError:\n",
    " #            with open(self.index_file, 'wb') as file:\n",
    " #                # print(\"index creado\")\n",
    " #                pass\n",
    " # \n"
   ],
   "block_group": "c2e0cdc0e8ff4c99935a31d2e0cfbfb0",
   "outputs_reference": null,
   "content_dependencies": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T03:11:59.814032Z",
     "start_time": "2024-11-13T03:11:52.401223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test preprocess songs\n",
    "index = InvertIndexSPIMI()\n",
    "index.build(r\".\\Postgres\\spotify_songs.csv\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In block: 0\n",
      "In block: 1\n",
      "In block: 2\n",
      "In block: 3\n",
      "In block: 4\n",
      "In block: 5\n",
      "In block: 6\n",
      "In block: 7\n",
      "In block: 8\n",
      "In block: 9\n",
      "In block: 10\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T02:00:01.451570Z",
     "start_time": "2024-11-13T02:00:01.448461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "arr = \"[(161, 3), (527, 16), (837, 4), (1144, 1), (1190, 18)]\"\n",
    "aux = eval(arr)\n",
    "print(aux)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(161, 3), (527, 16), (837, 4), (1144, 1), (1190, 18)]\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "deepnote_app_block_visible": true,
    "cell_id": "ad6a3745efa7403e9c4574ad2d0faedf",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": "",
   "block_group": "155a2121f1a34a99b3a52d979ff4cc68"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "code": true
      },
      "toCodePoint": 93,
      "fromCodePoint": 0
     }
    ],
    "deepnote_app_block_visible": true,
    "cell_id": "817231b7d83b42f790280fed1df1c1f6",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": "### Utilizar el siguiente algoritmo. Asegúrese que la similitud de dos documentos iguales sea 1. ",
   "block_group": "b182074cd4fc452e85624245319d4c14"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deepnote_img_src": "image-20241004-152440.png",
    "deepnote_img_width": "75%",
    "deepnote_app_block_visible": true,
    "cell_id": "d255e3e2c46e4dd694f7cdea0df5e5fc",
    "deepnote_cell_type": "image"
   },
   "source": "<img src=\"image-20241004-152440.png\" width=\"75%\" align=\"\" />",
   "block_group": "8c4caad1cce44834b0ad3aae3915425a"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "code": true
      },
      "toCodePoint": 24,
      "fromCodePoint": 0
     }
    ],
    "deepnote_app_block_visible": true,
    "cell_id": "fc4ba31965e74541a891506af3541fb3",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": "### Paso 2:\tProbar el Índice",
   "block_group": "b182074cd4fc452e85624245319d4c14"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "b66f1fdf",
    "execution_start": 1728075210544,
    "execution_millis": 649,
    "execution_context_id": "1e7e5f1c-d694-4140-b3f8-562293cc6b23",
    "deepnote_to_be_reexecuted": false,
    "deepnote_app_block_visible": true,
    "cell_id": "a6f62aa1c23240ca8be558794cacf0c8",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "end_time": "2024-10-24T09:54:34.051114Z",
     "start_time": "2024-10-24T09:54:33.995475Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Utilizar la siguiente coleccion de documentos para probar la eficiencia del indice\n",
    "dataton = pd.read_csv('df_total.csv')\n",
    "dataton.head()\n",
    "\n"
   ],
   "block_group": "8a2c44b475a740faa9150b193a912322",
   "outputs_reference": "s3:deepnote-cell-outputs-production/2de818f5-8fb7-4c1f-958a-4b11a8f7c719",
   "content_dependencies": null,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                url  \\\n",
       "0  https://www.larepublica.co/redirect/post/3201905   \n",
       "1  https://www.larepublica.co/redirect/post/3210288   \n",
       "2  https://www.larepublica.co/redirect/post/3240676   \n",
       "3  https://www.larepublica.co/redirect/post/3342889   \n",
       "4  https://www.larepublica.co/redirect/post/3427208   \n",
       "\n",
       "                                                news           Type  \n",
       "0  Durante el foro La banca articulador empresari...           Otra  \n",
       "1  El regulador de valores de China dijo el domin...   Regulaciones  \n",
       "2  En una industria históricamente masculina como...       Alianzas  \n",
       "3  Con el dato de marzo el IPC interanual encaden...  Macroeconomia  \n",
       "4  Ayer en Cartagena se dio inicio a la versión n...           Otra  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>news</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.larepublica.co/redirect/post/3201905</td>\n",
       "      <td>Durante el foro La banca articulador empresari...</td>\n",
       "      <td>Otra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.larepublica.co/redirect/post/3210288</td>\n",
       "      <td>El regulador de valores de China dijo el domin...</td>\n",
       "      <td>Regulaciones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.larepublica.co/redirect/post/3240676</td>\n",
       "      <td>En una industria históricamente masculina como...</td>\n",
       "      <td>Alianzas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.larepublica.co/redirect/post/3342889</td>\n",
       "      <td>Con el dato de marzo el IPC interanual encaden...</td>\n",
       "      <td>Macroeconomia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.larepublica.co/redirect/post/3427208</td>\n",
       "      <td>Ayer en Cartagena se dio inicio a la versión n...</td>\n",
       "      <td>Otra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T09:54:36.607940Z",
     "start_time": "2024-10-24T09:54:36.602963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mostrarDocumentos(result):\n",
    "    i = 1\n",
    "    result_news = []\n",
    "    ids = []\n",
    "    urls = []\n",
    "    scores = []\n",
    "    for resuldato in result:\n",
    "        # info_new = \"Rank:\" + str(i)+ \"Url :\"+ dataton[\"url\"][resuldato[0]]+ \"score: \"+ str(resuldato[1])\n",
    "        #result_news.append(info_new)\n",
    "        ids.append(str(i))\n",
    "        urls.append(dataton[\"url\"][resuldato[0]])\n",
    "        scores.append(str(resuldato[1]))\n",
    "        i = i + 1\n",
    "    df_news = pd.DataFrame({\"ID\": ids, \"URL\": urls, \"Score\": scores})\n",
    "    return df_news"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "8b7c87b5",
    "execution_start": 1728075214133,
    "execution_millis": 2,
    "execution_context_id": "1e7e5f1c-d694-4140-b3f8-562293cc6b23",
    "deepnote_app_block_visible": true,
    "cell_id": "c701e541247a40499c83012481e383ee",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "end_time": "2024-10-24T09:54:47.020596Z",
     "start_time": "2024-10-24T09:54:38.319137Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "index = InvertIndex(\"indice11.dat\")\n",
    "index.load_index()\n",
    "index.building(dataton, 1)  #El texto a procesar esta en la posicion 1\n",
    "# \n",
    "Query1 = \"El pais de China y su cooperacion\"\n",
    "result = index.retrieval(Query1, 10)\n",
    "\n",
    "\n",
    "# Proponer 3 consultas de prueba adiconales"
   ],
   "block_group": "05a75acaf71f43ce94cdf501e2771598",
   "outputs_reference": "s3:deepnote-cell-outputs-production/e59a9e25-5e97-4b6a-bb7a-7000db361f3d",
   "content_dependencies": null,
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b824a2a4-ec75-4e0c-9c8d-ae3f8e552746' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T09:54:49.227306Z",
     "start_time": "2024-10-24T09:54:49.218209Z"
    }
   },
   "cell_type": "code",
   "source": "mostrarDocumentos(result)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID                                               URL                Score\n",
       "0   1  https://www.larepublica.co/redirect/post/3210288   0.7384733783760663\n",
       "1   2  https://www.larepublica.co/redirect/post/3210674   0.3765711976841568\n",
       "2   3  https://www.larepublica.co/redirect/post/3272619  0.29932273809980553\n",
       "3   4  https://www.larepublica.co/redirect/post/3400324  0.28182843669299396\n",
       "4   5  https://www.larepublica.co/redirect/post/3268483  0.25770113961402363\n",
       "5   6  https://www.larepublica.co/redirect/post/3202517  0.22445755100245576\n",
       "6   7  https://www.larepublica.co/redirect/post/3294146  0.22413957361890074\n",
       "7   8  https://www.larepublica.co/redirect/post/3405368  0.20006317449382055\n",
       "8   9  https://www.larepublica.co/redirect/post/3375722  0.19922673830097193\n",
       "9  10  https://www.larepublica.co/redirect/post/2963453  0.18592112008076767"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3210288</td>\n",
       "      <td>0.7384733783760663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3210674</td>\n",
       "      <td>0.3765711976841568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3272619</td>\n",
       "      <td>0.29932273809980553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3400324</td>\n",
       "      <td>0.28182843669299396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3268483</td>\n",
       "      <td>0.25770113961402363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3202517</td>\n",
       "      <td>0.22445755100245576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3294146</td>\n",
       "      <td>0.22413957361890074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3405368</td>\n",
       "      <td>0.20006317449382055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3375722</td>\n",
       "      <td>0.19922673830097193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/2963453</td>\n",
       "      <td>0.18592112008076767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Consultas adicionales"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T09:54:51.539509Z",
     "start_time": "2024-10-24T09:54:51.499277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Query2 = \"Empresas mas sostenibles del mundo\"\n",
    "result2 = index.retrieval(Query2, 5)\n",
    "mostrarDocumentos(result2)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  ID                                                URL                Score\n",
       "0  1  https://www.bbva.com/es/sostenibilidad/bbva-ot...   0.4005098937746341\n",
       "1  2  https://www.bbva.com/es/sostenibilidad/que-es-...  0.37965433294693923\n",
       "2  3  https://www.bbva.com/es/sostenibilidad/banca-p...   0.3665823694656286\n",
       "3  4  https://www.bbva.com/es/sostenibilidad/bbva-el...  0.33341185357384023\n",
       "4  5  https://www.bbva.com/es/mx/sostenibilidad/las-...  0.33161216878346766"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.bbva.com/es/sostenibilidad/bbva-ot...</td>\n",
       "      <td>0.4005098937746341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.bbva.com/es/sostenibilidad/que-es-...</td>\n",
       "      <td>0.37965433294693923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.bbva.com/es/sostenibilidad/banca-p...</td>\n",
       "      <td>0.3665823694656286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.bbva.com/es/sostenibilidad/bbva-el...</td>\n",
       "      <td>0.33341185357384023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://www.bbva.com/es/mx/sostenibilidad/las-...</td>\n",
       "      <td>0.33161216878346766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T09:54:53.601067Z",
     "start_time": "2024-10-24T09:54:53.560774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Query3 = \"Uso de la tecnologia en la educacion\"\n",
    "result3 = index.retrieval(Query3, 5)\n",
    "mostrarDocumentos(result3)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  ID                                                URL                Score\n",
       "0  1  https://www.bbva.com/es/sostenibilidad/mi-hija...   1.0707990573138608\n",
       "1  2  https://www.bbva.com/es/sostenibilidad/cuatro-...   0.6787281394465713\n",
       "2  3   https://www.larepublica.co/redirect/post/3190074   0.6484372042404604\n",
       "3  4   https://www.larepublica.co/redirect/post/3238772   0.5496885615670838\n",
       "4  5   https://www.larepublica.co/redirect/post/3461399  0.42930244739174467"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.bbva.com/es/sostenibilidad/mi-hija...</td>\n",
       "      <td>1.0707990573138608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.bbva.com/es/sostenibilidad/cuatro-...</td>\n",
       "      <td>0.6787281394465713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3190074</td>\n",
       "      <td>0.6484372042404604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3238772</td>\n",
       "      <td>0.5496885615670838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3461399</td>\n",
       "      <td>0.42930244739174467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T09:54:55.014469Z",
     "start_time": "2024-10-24T09:54:54.978546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Query4 = \"Salud y bienestar en la sociedad\"\n",
    "result4 = index.retrieval(Query4, 10)\n",
    "mostrarDocumentos(result4)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID                                                URL                Score\n",
       "0   1  https://www.bbva.com/es/bienestar-psicologico-...  0.46765076194006755\n",
       "1   2  https://www.bbva.com/es/es/el-crecimiento-de-l...   0.2716554022237061\n",
       "2   3  https://www.bbva.com/es/diagnosticos-precoces-...  0.24011456999499284\n",
       "3   4   https://www.larepublica.co/redirect/post/3236895  0.23928459884318612\n",
       "4   5  https://www.bbva.com/es/bbva-y-barcelona-healt...   0.1842586905019784\n",
       "5   6   https://www.larepublica.co/redirect/post/3403198  0.16651893486089497\n",
       "6   7  https://www.bbva.com/es/sostenibilidad/aumenta...   0.1534335849189078\n",
       "7   8  https://www.bbva.com/es/sostenibilidad/aumenta...   0.1534335849189078\n",
       "8   9  https://www.bbva.com/es/sostenibilidad/aumenta...   0.1534335849189078\n",
       "9  10   https://www.larepublica.co/redirect/post/3314390   0.1446902152812807"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.bbva.com/es/bienestar-psicologico-...</td>\n",
       "      <td>0.46765076194006755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.bbva.com/es/es/el-crecimiento-de-l...</td>\n",
       "      <td>0.2716554022237061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.bbva.com/es/diagnosticos-precoces-...</td>\n",
       "      <td>0.24011456999499284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3236895</td>\n",
       "      <td>0.23928459884318612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://www.bbva.com/es/bbva-y-barcelona-healt...</td>\n",
       "      <td>0.1842586905019784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3403198</td>\n",
       "      <td>0.16651893486089497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>https://www.bbva.com/es/sostenibilidad/aumenta...</td>\n",
       "      <td>0.1534335849189078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>https://www.bbva.com/es/sostenibilidad/aumenta...</td>\n",
       "      <td>0.1534335849189078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>https://www.bbva.com/es/sostenibilidad/aumenta...</td>\n",
       "      <td>0.1534335849189078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>https://www.larepublica.co/redirect/post/3314390</td>\n",
       "      <td>0.1446902152812807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T09:54:57.093818Z",
     "start_time": "2024-10-24T09:54:57.089659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def wrapper(query, k):\n",
    "    result = index.retrieval(query, k)\n",
    "    return mostrarDocumentos(result)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T09:55:00.485897Z",
     "start_time": "2024-10-24T09:55:00.445538Z"
    }
   },
   "cell_type": "code",
   "source": "print(wrapper(\"El pais de China y su cooperacion\", 5))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ID                                               URL                Score\n",
      "0  1  https://www.larepublica.co/redirect/post/3210288   0.7384733783760663\n",
      "1  2  https://www.larepublica.co/redirect/post/3210674   0.3765711976841568\n",
      "2  3  https://www.larepublica.co/redirect/post/3272619  0.29932273809980553\n",
      "3  4  https://www.larepublica.co/redirect/post/3400324  0.28182843669299396\n",
      "4  5  https://www.larepublica.co/redirect/post/3268483  0.25770113961402363\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T09:55:14.542799Z",
     "start_time": "2024-10-24T09:55:10.846102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=wrapper,\n",
    "    inputs=[gr.Text(label=\"Query\"), gr.Slider(label=\"Top Scores\")],\n",
    "    outputs=[gr.Dataframe(\n",
    "        headers=[\"ID\", \"Url\", \"Score\"],\n",
    "        datatype=[\"str\", \"str\", \"str\"],\n",
    "    )],\n",
    "    title=\"Proyecto DB2\",\n",
    "    examples=[\n",
    "        [\"El pais de China y su cooperacion\", 5],\n",
    "        [\"Salud y bienestar en la sociedad\", 10],\n",
    "    ],\n",
    "    theme='HaleyCH/HaleyCH_Theme'\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T09:55:35.366599Z",
     "start_time": "2024-10-24T09:55:35.193571Z"
    }
   },
   "cell_type": "code",
   "source": "# demo.close()\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T09:55:17.285325Z",
     "start_time": "2024-10-24T09:55:16.795352Z"
    }
   },
   "cell_type": "code",
   "source": "demo.launch()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "deepnote_persisted_session": {
   "createdAt": "2024-05-23T14:46:04.322Z"
  },
  "deepnote_app_layout": "powerful-article",
  "deepnote_app_reactivity_enabled": true,
  "deepnote_notebook_id": "0f6751b6349d4dc18cbbb391b3b45a06",
  "deepnote_execution_queue": [],
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 }
}
